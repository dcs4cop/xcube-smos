{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#xcube-smos","title":"xcube-smos","text":"<p>User-defined datacubes from SMOS Level-2 data</p> <p><code>xcube-smos</code> is a Python package and xcube plugin that adds a  data store  named <code>smos</code> to xcube. The data store is used to  access ESA SMOS Level-2 data  in form of analysis-ready geospatial datacubes with the dimensions  <code>time</code>, <code>lat</code>, and <code>lon</code>. The datacubes are computed on-the-fly from the SMOS  data archive <code>s3://EODATA/SMOS</code> hosted on CREODIAS.</p>"},{"location":"#usage","title":"Usage","text":"<p>After installation, data access is as easy as follows:</p> <pre><code>from xcube.core.store import new_data_store\n\nstore = new_data_store(\"smos\", **credentials)\ndatacube = store.open_data(\n    \"SMOS-L2C-SM\", \n    time_range=(\"2022-01-01\", \"2022-01-06\"),\n    bbox=(0, 40, 20, 60)\n)\n</code></pre> <p>Above, a datacube of type xarray.Dataset for SMOS Soil Moisture has been obtained. To access SMOS Ocean Salinity data use the identifier <code>\"SMOS-L2C-OS\"</code>. </p>"},{"location":"#spatial-coverage-and-resolution","title":"Spatial coverage and resolution","text":"<p>The SMOS data is provided globally or for a custom area of interest using a geographic projection (<code>EPSG:4326</code> aka WGS84,  World Geodetic System 1984). </p> <p>You can choose from five spatial resolutions by specifying a resolution  level ranging from zero to four. Zero refers to a resolution of  360/8192 ~ 0.044 degrees ~ 4.88 km. Higher levels subsequently increase the  resolution by a factor of two.</p> <p>Note</p> <p>The native spatial resolution of SMOS data is roughly 25 km.  <code>xcube-smos</code> performs an oversampling of the data to ensure no information is lost during spatial projection. It therefore uses a nearest-neighbor  resampling at higher resolution involving pixel duplication. </p>"},{"location":"#temporal-coverage-and-resolution","title":"Temporal coverage and resolution","text":"<p>The SMOS satellite completes one orbit approximately every 100.1 minutes. Therefore, up to 29 (number of orbits times two) level-2 data products are  provided per day and included in the datasets as individual time steps datasets. <code>xcube-smos</code> does not perform any aggregation in the time dimension. </p>"},{"location":"#variables","title":"Variables","text":"<p>The output of the data store are a SMOS Level-2C raster datacubes comprising  a number of geophysical data variables with the dimensions <code>time</code>, <code>lat</code>,  and <code>lon</code>. The variables depend on the selected SMOS product type, either Soil Moisture or Ocean Salinity.</p> <p>Soil Moisture datacubes of type <code>SMOS-L2C-SM</code> contain the following variables:</p> Variable Type Units Soil_Moisture float32 m3 m-3 Soil_Moisture_DQX float32 m3 m-3 Chi_2 uint8 - Chi_2_P uint8 - N_RFI_Y uint16 - N_RFI_X uint16 - RFI_Prob uint8 - <p>Ocean Salinity datacubes of type <code>SMOS-L2C-OC</code> contain the following variables:</p> Variable Type Units SSS_anom float32 psu SSS_corr float32 psu Sigma_SSS_anom float32 psu Sigma_SSS_corr float32 psu Dg_quality_SSS_anom uint16 - Dg_quality_SSS_corr uint16 - Dg_chi2_corr uint16 - Dg_RFI_X uint16 - Dg_RFI_Y uint16 - Coast_distance uint8 - Mean_acq_time float32 dd X_swath float32 m"},{"location":"about/","title":"About xcube-smos","text":""},{"location":"about/#changelog","title":"Changelog","text":"<p>You can find the complete <code>xcube-smos</code> changelog  here. </p>"},{"location":"about/#reporting","title":"Reporting","text":"<p>If you have suggestions, ideas, feature requests, or if you have identified a malfunction or error, then please  post an issue. </p>"},{"location":"about/#development","title":"Development","text":"<p>You can install <code>xcube-smos</code> directly from its GitHub repository into a xcube environment created with mamba (recommended) or conda.</p> <pre><code>mamba create -n xcube -c conda-forge xcube\nmamba activate xcube\ngit clone https://github.com/dcs4cop/xcube-smos.git\ncd xcube-smos\npip install --verbose --no-deps --editable .\n</code></pre>"},{"location":"about/#testing-and-coverage","title":"Testing and Coverage","text":"<p><code>xcube-smos</code> uses pytest for unit-level testing  and code coverage analysis.</p> <pre><code>pytest --cov=xcube-smos tests\n</code></pre>"},{"location":"about/#code-style","title":"Code Style","text":"<p><code>xcube-smos</code> source code is formatted using the black tool.</p> <pre><code>black xcube-smos\nblack tests\n</code></pre>"},{"location":"about/#documentation","title":"Documentation","text":"<p><code>xcube-smos</code> documentation is built using the mkdocs tool.</p> <pre><code>pip install -r requirements-doc.txt\n\nmkdocs build\nmkdocs serve\nmkdocs gh-deploy\n</code></pre>"},{"location":"about/#license","title":"License","text":"<p><code>xcube-smos</code> is open source made available under the terms and conditions of the  MIT License.</p> <p>Copyright \u00a9 2024 Brockmann Consult Development</p>"},{"location":"dev/","title":"xcube-smos Internals","text":""},{"location":"dev/#code-installation","title":"Code installation","text":""},{"location":"dev/#for-users","title":"For users","text":"<p>xcube-smos end users can install xcube-smos directly from its git repository into an xcube environment created with mamba (recommended) or conda.</p> <pre><code>mamba create -n xcube -c conda-forge xcube\nmamba activate xcube\ngit clone https://github.com/dcs4cop/xcube-smos.git\ncd xcube-smos\npip install --verbose --no-deps --editable .\n</code></pre>"},{"location":"guide/","title":"User Guide","text":"In\u00a0[17]: Copied! <pre>from xcube.core.store import new_data_store\n\nstore = new_data_store(\"smos\", cache_path=\"./nc_cache\")\n</pre> from xcube.core.store import new_data_store  store = new_data_store(\"smos\", cache_path=\"./nc_cache\") <p>The data store parameters you can pass to the <code>new_data_store()</code> function depend on the data store identifier used. For the data store named  <code>\"smos\"</code> the following arguments can be provided:</p> <ul> <li><code>cache_path</code>: str - Path to local cache directory for raw, remote SMOS files. Useful if you work on a known temporal subset of SMOS data. A file in the local cache does not need to be fetched from remote.</li> <li><code>source_path</code>: str - Path or URL into SMOS archive filesystem.</li> <li><code>source_protocol</code>: str - Protocol name for the SMOS archive filesystem.</li> <li><code>source_storage_options</code>: dict - Storage options for the SMOS archive filesystem.</li> <li><code>xarray_kwargs</code>: dict - Extra keyword arguments accepted by xarray.open_dataset.</li> <li><code>**source_storage_options_kwargs</code> - keyword-argument form of <code>source_storage_options</code></li> </ul> <p>Because of <code>**source_storage_options_kwargs</code> you can pass storage options directly to the <code>new_data_store()</code> call, such as:</p> <ul> <li><code>key</code>: str - Access key identifier for the CREODIAS storage, defaults to value of environment variable <code>CREODIAS_S3_KEY</code>.</li> <li><code>secret</code>: str - Secret access key for the CREODIAS storage, defaults to value of environment variable <code>CREODIAS_S3_SECRET</code>.</li> </ul> In\u00a0[\u00a0]: Copied! <pre># First we let xarray render datasets as text.\n# Done for documentation generation only.\nimport xarray as xr\nxr.set_options(display_style=\"text\")\n</pre> # First we let xarray render datasets as text. # Done for documentation generation only. import xarray as xr xr.set_options(display_style=\"text\") <p>Here the Soil Moisture dataset is opened for a 2-day coverage:</p> In\u00a0[3]: Copied! <pre>sm_ds = store.open_data(\"SMOS-L2C-SM\", \n                        time_range=[\"2024-01-01\", \"2024-01-02\"])\nsm_ds\n</pre> sm_ds = store.open_data(\"SMOS-L2C-SM\",                          time_range=[\"2024-01-01\", \"2024-01-02\"]) sm_ds Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 29GB\nDimensions:            (time: 31, lat: 4032, lon: 8192, bnds: 2)\nCoordinates:\n  * lat                (lat) float64 32kB 88.57 88.53 88.48 ... -88.53 -88.57\n  * lon                (lon) float64 66kB -180.0 -179.9 -179.9 ... 179.9 180.0\n  * time               (time) datetime64[ns] 248B 2024-01-01T00:27:26.980000 ...\n    time_bnds          (time, bnds) datetime64[ns] 496B dask.array&lt;chunksize=(31, 2), meta=np.ndarray&gt;\nDimensions without coordinates: bnds\nData variables:\n    Chi_2              (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Chi_2_P            (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    N_RFI_X            (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    N_RFI_Y            (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    RFI_Prob           (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Soil_Moisture      (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Soil_Moisture_DQX  (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;</pre> In\u00a0[4]: Copied! <pre>sm_ds.Soil_Moisture\n</pre> sm_ds.Soil_Moisture Out[4]: <pre>&lt;xarray.DataArray 'Soil_Moisture' (time: 31, lat: 4032, lon: 8192)&gt; Size: 4GB\ndask.array&lt;open_dataset-Soil_Moisture, shape=(31, 4032, 8192), dtype=float32, chunksize=(1, 4032, 8192), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * lat      (lat) float64 32kB 88.57 88.53 88.48 88.44 ... -88.48 -88.53 -88.57\n  * lon      (lon) float64 66kB -180.0 -179.9 -179.9 ... 179.9 179.9 180.0\n  * time     (time) datetime64[ns] 248B 2024-01-01T00:27:26.980000 ... 2024-0...\nAttributes:\n    units:    m3 m-3</pre> <p>The SMOS data store does not perform any data aggregation in the <code>time</code> dimension. The SMOS satellite completes one orbit approximately every 100.1 minutes, that's why there are around 30 time steps included in a 2-day coverage. A single time step contains data of only a half orbit:</p> In\u00a0[5]: Copied! <pre>sm_ds.Soil_Moisture.isel(time=4).plot.imshow(figsize=(10, 5), vmax=0.5)\n</pre> sm_ds.Soil_Moisture.isel(time=4).plot.imshow(figsize=(10, 5), vmax=0.5) Out[5]: <pre>&lt;matplotlib.image.AxesImage at 0x1b05900b590&gt;</pre> <p>All orbits aggregated:</p> In\u00a0[6]: Copied! <pre>sm_ds.Soil_Moisture.mean(\"time\").plot.imshow(figsize=(10, 5), vmax=0.5)\n</pre> sm_ds.Soil_Moisture.mean(\"time\").plot.imshow(figsize=(10, 5), vmax=0.5) Out[6]: <pre>&lt;matplotlib.image.AxesImage at 0x1b00050c2f0&gt;</pre> <p>Same for an Ocean Salinity dataset:</p> In\u00a0[7]: Copied! <pre>os_ds = store.open_data(\"SMOS-L2C-OS\", \n                        time_range=[\"2024-01-01\", \"2024-01-02\"])\nos_ds\n</pre> os_ds = store.open_data(\"SMOS-L2C-OS\",                          time_range=[\"2024-01-01\", \"2024-01-02\"]) os_ds Out[7]: <pre>&lt;xarray.Dataset&gt; Size: 44GB\nDimensions:              (time: 28, lat: 4032, lon: 8192, bnds: 2)\nCoordinates:\n  * lat                  (lat) float64 32kB 88.57 88.53 88.48 ... -88.53 -88.57\n  * lon                  (lon) float64 66kB -180.0 -179.9 -179.9 ... 179.9 180.0\n  * time                 (time) datetime64[ns] 224B 2024-01-01T01:17:31.81900...\n    time_bnds            (time, bnds) datetime64[ns] 448B dask.array&lt;chunksize=(28, 2), meta=np.ndarray&gt;\nDimensions without coordinates: bnds\nData variables:\n    Coast_distance       (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Dg_RFI_X             (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Dg_RFI_Y             (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Dg_chi2_corr         (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Dg_quality_SSS_anom  (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Dg_quality_SSS_corr  (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Mean_acq_time        (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    SSS_anom             (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    SSS_corr             (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Sigma_SSS_anom       (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    Sigma_SSS_corr       (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;\n    X_swath              (time, lat, lon) float32 4GB dask.array&lt;chunksize=(1, 4032, 8192), meta=np.ndarray&gt;</pre> In\u00a0[8]: Copied! <pre>os_ds.SSS_corr.isel(time=3).plot.imshow(figsize=(10, 5))\n</pre> os_ds.SSS_corr.isel(time=3).plot.imshow(figsize=(10, 5)) Out[8]: <pre>&lt;matplotlib.image.AxesImage at 0x1b000145b80&gt;</pre> <p>Zoomed:</p> In\u00a0[9]: Copied! <pre>os_ds.SSS_corr.isel(time=3).sel(lon=slice(20, 45), lat=slice(-55, -70)).plot.imshow()\n</pre> os_ds.SSS_corr.isel(time=3).sel(lon=slice(20, 45), lat=slice(-55, -70)).plot.imshow() Out[9]: <pre>&lt;matplotlib.image.AxesImage at 0x1b000562a50&gt;</pre> In\u00a0[10]: Copied! <pre>ds_iter = store.open_data(\"SMOS-L2C-OS\", \n                          opener_id=\"smosdsiter:zarr:smos\",\n                          time_range=[\"2024-01-01\", \"2024-01-02\"])\nds_iter\n</pre> ds_iter = store.open_data(\"SMOS-L2C-OS\",                            opener_id=\"smosdsiter:zarr:smos\",                           time_range=[\"2024-01-01\", \"2024-01-02\"]) ds_iter Out[10]: <pre>&lt;xcube_smos.dsiter.SmosDatasetIterator at 0x1b0037ab320&gt;</pre> <p>The main use case of dataset iterators is persisting large datacubes by subsequently appending slice dataset along the <code>time</code> dimension at stable memory and CPU consumption. For example, you can use the zappend tool to write larger datacubes like this:</p> <pre>zappend(ds_iter, target_dir=\"SMOS-L2C-OC.zarr\")\n</pre> In\u00a0[11]: Copied! <pre>ml_ds = store.open_data(\"SMOS-L2C-OS\", \n                        opener_id=\"mldataset:zarr:smos\",\n                        time_range=[\"2024-01-01\", \"2024-01-02\"])\nml_ds\n</pre> ml_ds = store.open_data(\"SMOS-L2C-OS\",                          opener_id=\"mldataset:zarr:smos\",                         time_range=[\"2024-01-01\", \"2024-01-02\"]) ml_ds Out[11]: <pre>&lt;xcube_smos.mldataset.l2cube.SmosL2Cube at 0x1b0015e8170&gt;</pre> <p>The returned multi-resolution dataset <code>ml_ds</code> is just a container for ordinary datasets oy type <code>xarray.Dataset</code> at different spatial resolutions:</p> In\u00a0[12]: Copied! <pre>for level in range(ml_ds.num_levels):\n    ds = ml_ds.get_dataset(level)\n    print(f\"Level {level}: {ds.sizes}\")\n</pre> for level in range(ml_ds.num_levels):     ds = ml_ds.get_dataset(level)     print(f\"Level {level}: {ds.sizes}\") <pre>Level 0: Frozen({'time': 28, 'lat': 4032, 'lon': 8192, 'bnds': 2})\nLevel 1: Frozen({'time': 28, 'lat': 2016, 'lon': 4096, 'bnds': 2})\nLevel 2: Frozen({'time': 28, 'lat': 1008, 'lon': 2048, 'bnds': 2})\nLevel 3: Frozen({'time': 28, 'lat': 504, 'lon': 1024, 'bnds': 2})\nLevel 4: Frozen({'time': 28, 'lat': 252, 'lon': 512, 'bnds': 2})\n</pre> In\u00a0[13]: Copied! <pre>from xcube.core.store import get_data_store_params_schema\n\nschema = get_data_store_params_schema(\"smos\")\nschema\n</pre> from xcube.core.store import get_data_store_params_schema  schema = get_data_store_params_schema(\"smos\") schema Out[13]: <pre>&lt;xcube.util.jsonschema.JsonObjectSchema at 0x1b0568f1af0&gt;</pre> In\u00a0[14]: Copied! <pre># For example:\nfor p_name, p_schema in schema.properties.items():\n    print(f\"* `{p_name}: {p_schema.type} - {p_schema.description or p_schema.title}\")\n</pre> # For example: for p_name, p_schema in schema.properties.items():     print(f\"* `{p_name}: {p_schema.type} - {p_schema.description or p_schema.title}\") <pre>* `source_path: string - Path or URL into SMOS archive filesystem.\n* `source_protocol: string - Protocol name for the SMOS archive filesystem.\n* `source_storage_options: object - See fsspec documentation for specific filesystems.\n* `cache_path: string - Path to local cache directory. Must be given, if file caching is desired.\n* `xarray_kwargs: object - See xarray documentation for allowed keywords.\n</pre> <p>You can use <code>schema.to_dict()</code> get a JSON-serializable dictionary.</p> In\u00a0[15]: Copied! <pre>schema = store.get_open_data_params_schema(opener_id=\"dataset:zarr:smos\")\nschema\n</pre> schema = store.get_open_data_params_schema(opener_id=\"dataset:zarr:smos\") schema Out[15]: <pre>&lt;xcube.util.jsonschema.JsonObjectSchema at 0x1b05831f200&gt;</pre> In\u00a0[16]: Copied! <pre>for p_name, p_schema in schema.properties.items():\n    print(f\"* `{p_name}: {p_schema.type} - {p_schema.description or p_schema.title}\")\n</pre> for p_name, p_schema in schema.properties.items():     print(f\"* `{p_name}: {p_schema.type} - {p_schema.description or p_schema.title}\") <pre>* `time_range: array - Time range given as pair of start and stop dates. Dates must be given using format 'YYYY-MM-DD'. Start and stop are inclusive.\n* `bbox: array - Bounding box [x1,y1, x2,y2] in geographical coordinates\n* `res_level: integer - Spatial resolution level in the range 0 to 4. Zero refers to the max. resolution of 0.0439453125 degrees.\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"guide/#user-guide","title":"User Guide\u00b6","text":"<p>The SMOS data store is an xcube plugin that provides SMOS datasets through the xcube data store interface. You first obtain an instance of the SMOS data store, then you use this store instance to retrieve customised SMOS datasets tailored to your needs.</p>"},{"location":"guide/#obtaining-the-data-store","title":"Obtaining the Data Store\u00b6","text":"<p>After installation and once you have your credentials at hand, you can obtain an instance of the SMOS data store by its name <code>\"smos\"</code> and using the xcube function <code>new_data_store()</code> function. (Many other xcube data stores can be used in the same way, refer to the xcube documentation for more information). In the following it is assumed that the environment variables <code>CREODIAS_S3_KEY</code> and <code>CREODIAS_S3_SECRET</code> have been set:</p>"},{"location":"guide/#data-access","title":"Data Access\u00b6","text":"<p>All xcube data stores provide a <code>store.open_data()</code> method to access the data. It has one required positional argument <code>data_id</code> which identifies the data(set) to be opened. The SMOS store provides two datasets, they are</p> <ul> <li><code>\"SMOS-L2C-SM\"</code> - SMOS Level-2C Soil Moisture</li> <li><code>\"SMOS-L2C-OS\"</code> - SMOS Level-2C Ocean Salinity</li> </ul> <p>In addition  to the first <code>data_id</code> argument the following keyword arguments are defined:</p> <ul> <li><code>time_range</code>: The time range <code>(start, stop)</code> given as pair of start and stop dates either as <code>tuple</code> or <code>list</code> of <code>str</code>. Dates must be given using format <code>\"YYYY-MM-DD\"</code>. Start and stop are inclusive. This parameter is required.</li> <li><code>bbox</code>: Bounding box in geographical coordinates given as <code>(x1,y1, x2,y2)</code> either as <code>tuple</code> or <code>list</code> of <code>float</code>. Defaults to global coverage resulting in a spatial image resolution of 8192 x 4032 pixels.</li> <li><code>res_level</code>: Spatial resolution level in the range 0 to 4. Actual resolution in degrees is <code>(360/8192) / 2 ** res_level</code>. Defaults to <code>0</code>. Not applicable to multi-resolution datasets, see below.</li> <li><code>l2_product_cache_size</code>: Size of the SMOS L2 product cache given as maximum number of SMOS L2 products to be cached in memory. Can drastically improve performance if you need to randomly access datacubes in the time dimension. Does not apply to dataset iterators, see below.</li> </ul>"},{"location":"guide/#datasets","title":"Datasets\u00b6","text":"<p>To get a dataset from the data store, you must pass its dataset identifier and the time range, other parameters are optional.</p>"},{"location":"guide/#dataset-iterators","title":"Dataset Iterators\u00b6","text":"<p>Use <code>opener_id=\"smosdsiter:zarr:smos\"</code> to receive SMOS data in form of an iterator of datasets of type <code>xarray.Dataset</code>. The returned datasets are iterated through the <code>time</code> dimension, hence individual datasets have a <code>time</code> dimension of size one.</p>"},{"location":"guide/#multi-resolution-datasets","title":"Multi-Resolution Datasets\u00b6","text":"<p>Use <code>opener_id=\"mldataset:zarr:smos\"</code> to receive SMOS data in form of a multi-resolution dataset:</p>"},{"location":"guide/#parameter-schemas","title":"Parameter Schemas\u00b6","text":"<p>This section describes how the various parameters used by SMOS data store can be inspected programmatically.</p>"},{"location":"guide/#schema-for-the-data-store-parameters","title":"Schema for the Data Store Parameters\u00b6","text":"<p>The xcube function <code>get_data_store_params_schema()</code> outputs the allowed parameters for a given data store as a JSON Schema object:</p>"},{"location":"guide/#schema-for-the-open-parameters","title":"Schema for the Open Parameters\u00b6","text":"<p>Using the <code>store.get_open_data_params_schema()</code> method you can inspect the allowed parameters for the <code>store.open_data()</code> method, which is used to open SMOS datacubes.</p>"},{"location":"start/","title":"Getting Started","text":""},{"location":"start/#credentials","title":"Credentials","text":"<p>The xcube SMOS data store directly accesses  SMOS data in its S3 archive on  CREODIAS. Therefore, the data store requires your  credentials. If not already done, create an account on CREODIAS and follow  the instructions to  generate your access key and secret.</p> <p>Once you have received your credentials, you may consider setting the environment  variables <code>CREODIAS_S3_KEY</code> and <code>CREODIAS_S3_SECRET</code>. If you do so, you can omit the <code>key</code> and <code>secret</code> arguments passed to the data store.</p>"},{"location":"start/#installation","title":"Installation","text":"<p>You can install xcube-smos as a conda package:</p> <pre><code>conda install -c conda-forge xcube-smos\n</code></pre> <p>Or install it from its GitHub sources into a Python environment with xcube and its dependencies installed.</p> <pre><code>git clone https://github.com/dcs4cop/xcube-smos.git\ncd xcube-smos\npip install -ve .\n</code></pre>"},{"location":"start/#get-the-data","title":"Get the Data","text":"<p>You can now use the SMOS data store using the xcube <code>new_data_store()</code>  function and passing the store identifier <code>\"smos\"</code> and using your credentials. Then you use the store method <code>open_data()</code> to access the data:</p> <pre><code>from xcube.core.store import new_data_store\n\nstore = new_data_store(\"smos\", \n                       key=\"your access key\", \n                       secret=\"your access key secret\")\n\ndataset = store.open_data(data_id=\"SMOS-L2C-SM\",\n                          time_range=(\"2022-01-01\", \"2022-01-05\"), \n                          bbox=(5.87, 47.27, 15.03, 55.06),\n                          res_level=0)\n</code></pre> <p>There are a couple of parameters that can be passed to the <code>new_data_store()</code> function and the <code>open_data()</code> method. You can read more about it in the  user guide.</p>"}]}