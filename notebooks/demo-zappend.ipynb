{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ad0e83-27d4-4ac5-8138-72a0f84f167d",
   "metadata": {},
   "source": [
    "This NB demonstrates the xcube **SMOS L2C data store `smos`**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a5643-5385-4760-988b-fef2a20ac115",
   "metadata": {},
   "source": [
    "Inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e616dd7-63d8-42cf-bf5f-d7536baa3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_type = \"SMOS-L2C-SM\"\n",
    "# product_type = \"SMOS-L2C-OS\"\n",
    "time_range = \"2022-01-01/2022-01-03\"\n",
    "interval = \"1d\"  # or None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe3ab3b-8812-4195-a79b-111bda04524e",
   "metadata": {},
   "source": [
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5637ed4-abaf-476c-9f20-851c38517d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smos-20220101-20220103-1d.zarr'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_path = f'smos-{time_range.replace(\"-\", \"\").replace(\"/\", \"-\")}-{interval.lower()}.zarr'\n",
    "target_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85995e28-ae98-4d7f-a040-419931009977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from IPython.display import JSON\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from xcube.core.store import find_data_store_extensions\n",
    "from xcube.core.store import get_data_store_params_schema\n",
    "from xcube.core.store import new_data_store\n",
    "from zappend.api import zappend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ee2963-d5ad-4e45-b5c1-4b297760ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_ranges(time_range: str, interval: str | None):\n",
    "    one_sec = pd.Timedelta(\"1s\")\n",
    "    one_day = pd.Timedelta(\"1d\")\n",
    "\n",
    "    start_date, stop_date = time_range.split(\"/\", maxsplit=1)\n",
    "    interval_td = pd.Timedelta(interval) if interval else one_day\n",
    "    dates = pd.date_range(start_date, stop_date, freq=interval_td)\n",
    "\n",
    "    def to_date_str(date):\n",
    "        return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return [(to_date_str(dates[i]), to_date_str(dates[i+1] - one_sec)) \n",
    "            for i in range(len(dates) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8c7eec-1fb4-4d24-a9a7-8a326c9f64d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2022-01-01', '2022-01-01'), ('2022-01-02', '2022-01-02')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_ranges = get_time_ranges(time_range, interval)\n",
    "time_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c202cf-3378-472a-ba99-c755a05aa203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"creodias-credentials.json\") as f:\n",
    "    credentials = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ddf85f-1ab5-4094-899f-98149b809106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store = new_data_store(\n",
    "    'smos', \n",
    "    source_path=\"s3://EODATA\", \n",
    "    source_storage_options=dict(\n",
    "        endpoint_url=\"https://s3.cloudferro.com\", \n",
    "        anon=False, \n",
    "        **credentials\n",
    "    ),\n",
    "    cache_path=\"nc_cache\",\n",
    "    xarray_kwargs=dict(\n",
    "        engine=\"h5netcdf\"\n",
    "        #engine=\"netcdf4\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0731e9e0-e9fd-444f-a602-2aae2c95a713",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": [
       "SMOS-L2C-SM",
       "SMOS-L2C-OS"
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(store.list_data_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ecd2852-6a46-45ec-8355-449298016cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_datasets(store, product_type, time_ranges, interval):\n",
    "    \n",
    "    logger = logging.getLogger(\"notebook\")\n",
    "    \n",
    "    for time_range in time_ranges:        \n",
    "        ds_iterator = store.open_data(\n",
    "            product_type, \n",
    "            opener_id=\"dsiter:zarr:smos\",\n",
    "            time_range=time_range\n",
    "        )\n",
    "                \n",
    "        if interval is None:\n",
    "            # If we have no interval, we deliver the slices as-is.\n",
    "            yield from ds_iterator\n",
    "            \n",
    "        temp_path = f\"./temp-{'-'.join(time_range)}\"\n",
    "        if not os.path.exists(temp_path):\n",
    "            os.mkdir(temp_path)\n",
    "            \n",
    "        num_datasets = len(ds_iterator)\n",
    "            \n",
    "        slice_paths = []\n",
    "        for index, ds in enumerate(ds_iterator):\n",
    "            slice_path = f\"{temp_path}/slice-{index}.nc\"\n",
    "            logger.info(f\"Writing slice %d of %d to %s\", \n",
    "                        index + 1, num_datasets, slice_path)\n",
    "            ds.to_netcdf(slice_path, mode=\"w\")\n",
    "            slice_paths.append(slice_path)\n",
    "            \n",
    "        ds = xr.open_mfdataset(slice_paths, \n",
    "                               # engine=\"zarr\",\n",
    "                               combine=\"nested\", \n",
    "                               concat_dim=\"time\")\n",
    "\n",
    "        ds_mean = ds.mean(\"time\")\n",
    "        \n",
    "        # ds_mean has no time dimension, so we re-introduce it \n",
    "        ds_mean = ds_mean.expand_dims(\"time\", axis=0)\n",
    "        start, stop = pd.to_datetime(time_range)\n",
    "        ds_mean.coords[\"time\"] = xr.DataArray(\n",
    "            np.array([start + (stop - start) / 2]), \n",
    "            dims=\"time\", \n",
    "        )\n",
    "        ds_mean.coords[\"time_bnds\"] = xr.DataArray(\n",
    "            np.array([[start, stop]]), \n",
    "            dims=(\"time\", \"bnds\"),\n",
    "        )\n",
    "        \n",
    "        # Align encoding and attributes\n",
    "        for var_name, var in ds.variables.items():\n",
    "            mean_var = ds_mean.get(var_name)\n",
    "            if mean_var is not None:\n",
    "                mean_var.encoding.update(var.encoding)\n",
    "                mean_var.attrs.update(var.attrs)\n",
    "            \n",
    "        slice_file = temp_path + \".nc\"   \n",
    "        logger.info(f\"Writing mean slice to %s\", slice_file)\n",
    "        ds_mean.to_netcdf(slice_file, mode=\"w\")\n",
    "        \n",
    "        ds_mean.close()\n",
    "        ds_mean = None\n",
    "        ds.close()\n",
    "        ds = None\n",
    "        \n",
    "        logger.info(f\"Removing temporary %s\", temp_path)\n",
    "        shutil.rmtree(temp_path, ignore_errors=True)\n",
    "\n",
    "        # TODO: yield a slice source here, so that we can delete \n",
    "        #   the temporary slice_file after the slice has been \n",
    "        #   processed. See https://github.com/bcdev/zappend/issues/13\n",
    "        yield slice_file        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13413fa-1d08-41c7-9bbd-394e14c1bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "#generator = generate_datasets(store, product_type, time_ranges, interval)\n",
    "#ds_path = next(generator)\n",
    "#ds_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07912a4d-d945-44d5-9ee7-b3e8ca10b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with xr.open_dataset(ds_path) as ds:\n",
    "#     display(ds)\n",
    "#     display(ds.Soil_Moisture.plot.imshow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e707f8-16fa-47cf-85fe-274cc8a586f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zappend_config = {\n",
    "    \"target_dir\": \"./\" + target_path, \n",
    "    \n",
    "    \"fixed_dims\": {\n",
    "        \"lon\": 8192,\n",
    "        \"lat\": 4032\n",
    "    },\n",
    "    \n",
    "    \"append_dim\": \"time\",\n",
    "    \n",
    "    \"persist_mem_slices\": False,\n",
    "    \n",
    "    \"variables\": {\n",
    "        \"*\": {\n",
    "            \"encoding\": {\n",
    "                \"chunks\": [1, 4032 // 4, 8192 // 4]\n",
    "            }\n",
    "        },\n",
    "        \"time\": {\n",
    "            \"encoding\": {\n",
    "                \"chunks\": [100]\n",
    "            }\n",
    "        },\n",
    "        \"time_bnds\": {\n",
    "            \"encoding\": {\n",
    "                \"chunks\": [100, 2]\n",
    "            }\n",
    "        },\n",
    "        \"lat\": {\n",
    "            \"encoding\": {\n",
    "                \"chunks\": [4032]\n",
    "            }\n",
    "        },\n",
    "        \"lon\": {\n",
    "            \"encoding\": {\n",
    "                \"chunks\": [8192]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    # Log to the console.\n",
    "    # Note you could also configure the log output for dask here.\n",
    "    \"logging\": {\n",
    "        \"version\": 1,\n",
    "        \"formatters\": {\n",
    "            \"normal\": {\n",
    "                \"format\": \"%(asctime)s %(levelname)s %(message)s\",\n",
    "                \"style\": \"%\"\n",
    "            }\n",
    "        },\n",
    "        \"handlers\": {\n",
    "            \"console\": {\n",
    "                \"class\": \"logging.StreamHandler\",\n",
    "                \"formatter\": \"normal\"\n",
    "            }\n",
    "        },\n",
    "        \"loggers\": {\n",
    "            \"zappend\": {\n",
    "                \"level\": \"INFO\",\n",
    "                \"handlers\": [\"console\"]\n",
    "            },\n",
    "            \"notebook\": {\n",
    "                \"level\": \"INFO\",\n",
    "                \"handlers\": [\"console\"]\n",
    "            },\n",
    "            #\"xcube-smos\": {\n",
    "            #    \"level\": \"DEBUG\",\n",
    "            #    \"handlers\": [\"console\"]\n",
    "            #}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2067f8-ce17-4670-88db-bbc968104197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 14:15:12,462 INFO Writing slice 1 of 29 to ./temp-2022-01-01-2022-01-01/slice-0.nc\n",
      "2024-01-12 14:15:14,412 INFO Writing slice 2 of 29 to ./temp-2022-01-01-2022-01-01/slice-1.nc\n",
      "2024-01-12 14:15:16,309 INFO Writing slice 3 of 29 to ./temp-2022-01-01-2022-01-01/slice-2.nc\n",
      "2024-01-12 14:15:18,220 INFO Writing slice 4 of 29 to ./temp-2022-01-01-2022-01-01/slice-3.nc\n",
      "2024-01-12 14:15:20,106 INFO Writing slice 5 of 29 to ./temp-2022-01-01-2022-01-01/slice-4.nc\n",
      "2024-01-12 14:15:21,967 INFO Writing slice 6 of 29 to ./temp-2022-01-01-2022-01-01/slice-5.nc\n",
      "2024-01-12 14:15:23,941 INFO Writing slice 7 of 29 to ./temp-2022-01-01-2022-01-01/slice-6.nc\n",
      "2024-01-12 14:15:25,848 INFO Writing slice 8 of 29 to ./temp-2022-01-01-2022-01-01/slice-7.nc\n",
      "2024-01-12 14:15:28,192 INFO Writing slice 9 of 29 to ./temp-2022-01-01-2022-01-01/slice-8.nc\n",
      "2024-01-12 14:15:30,160 INFO Writing slice 10 of 29 to ./temp-2022-01-01-2022-01-01/slice-9.nc\n",
      "2024-01-12 14:15:32,080 INFO Writing slice 11 of 29 to ./temp-2022-01-01-2022-01-01/slice-10.nc\n",
      "2024-01-12 14:15:34,024 INFO Writing slice 12 of 29 to ./temp-2022-01-01-2022-01-01/slice-11.nc\n",
      "2024-01-12 14:15:35,927 INFO Writing slice 13 of 29 to ./temp-2022-01-01-2022-01-01/slice-12.nc\n",
      "2024-01-12 14:15:37,939 INFO Writing slice 14 of 29 to ./temp-2022-01-01-2022-01-01/slice-13.nc\n",
      "2024-01-12 14:15:39,816 INFO Writing slice 15 of 29 to ./temp-2022-01-01-2022-01-01/slice-14.nc\n",
      "2024-01-12 14:15:41,685 INFO Writing slice 16 of 29 to ./temp-2022-01-01-2022-01-01/slice-15.nc\n",
      "2024-01-12 14:15:43,559 INFO Writing slice 17 of 29 to ./temp-2022-01-01-2022-01-01/slice-16.nc\n",
      "2024-01-12 14:15:45,474 INFO Writing slice 18 of 29 to ./temp-2022-01-01-2022-01-01/slice-17.nc\n",
      "2024-01-12 14:15:47,381 INFO Writing slice 19 of 29 to ./temp-2022-01-01-2022-01-01/slice-18.nc\n",
      "2024-01-12 14:15:49,412 INFO Writing slice 20 of 29 to ./temp-2022-01-01-2022-01-01/slice-19.nc\n",
      "2024-01-12 14:15:51,317 INFO Writing slice 21 of 29 to ./temp-2022-01-01-2022-01-01/slice-20.nc\n",
      "2024-01-12 14:15:53,242 INFO Writing slice 22 of 29 to ./temp-2022-01-01-2022-01-01/slice-21.nc\n",
      "2024-01-12 14:15:55,171 INFO Writing slice 23 of 29 to ./temp-2022-01-01-2022-01-01/slice-22.nc\n",
      "2024-01-12 14:15:57,121 INFO Writing slice 24 of 29 to ./temp-2022-01-01-2022-01-01/slice-23.nc\n",
      "2024-01-12 14:15:59,019 INFO Writing slice 25 of 29 to ./temp-2022-01-01-2022-01-01/slice-24.nc\n",
      "2024-01-12 14:16:01,038 INFO Writing slice 26 of 29 to ./temp-2022-01-01-2022-01-01/slice-25.nc\n",
      "2024-01-12 14:16:02,904 INFO Writing slice 27 of 29 to ./temp-2022-01-01-2022-01-01/slice-26.nc\n",
      "2024-01-12 14:16:04,800 INFO Writing slice 28 of 29 to ./temp-2022-01-01-2022-01-01/slice-27.nc\n",
      "2024-01-12 14:16:06,702 INFO Writing slice 29 of 29 to ./temp-2022-01-01-2022-01-01/slice-28.nc\n",
      "2024-01-12 14:16:07,630 INFO Writing mean slice to ./temp-2022-01-01-2022-01-01.nc\n"
     ]
    }
   ],
   "source": [
    "generator = generate_datasets(store, product_type, time_ranges, interval)\n",
    "zappend(generator, config=zappend_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665720d-a9ad-4f82-a91d-e265ff01b3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
